*
* 											CLASS 01_New Producers and consumers
* 
* 
* 
* 		01. About changes in the service-fraud-detector
* 
* 			Let's start change the service and add a logic to understand if a value of a order is or not a fraud.
*  			Then, we are going to send messages from our service, cause we are baaaaaaad boys.
* 
* 			-> IMPORTANT: If we do execute the LogService BEFORE our the FraudService, who send messages to a new Topic, 
*			the LogService won't hear those messages. Why? Because when we use a pattern to hear the messages, the 
*			pattern will be applied ONLY when the service starts, but not later. In other words: since when it starts
*			we still doesn't have the FraudService with it's new topics running, it will not know those topics exists,
*			and, for that alone, it will not hear it.
*
*		02. About changes in Order of service-fraud-detector
*
*			Since we have a specific Order for each service, we make changes that only make sense inside that project. That
*			generates a trade-in-trade-off scenario: for a first, we don't have to add changes that does not make sense in
*			other scenarios. The problem is: we will have different models for each service. Do our project accepts that scenario?
*			Yes, so it's all sunny in Philly.
* 
* 		03. About the changes in KafkaService
*  
* 			Since we are now throwing exceptions in our consume methods (because we are going to send messages inside of the
* 			consume method from FraudService), we need to threat those exceptions. For now, we only will log in those exceptions.
* 
* 		04. About the new service CreateUserService
* 
* 			Our implementation will assume the service will run ONLY ONCE. This service will save the user information in a 
* 			SQLite database.
* 
* 			As we go further in the implementation of this service, one architectural decision is becoming clear: our user, when 
*			added, will not use the UniversalId as primary key, but the e-mail. When the person give their information, their
* 			identification will be the email, so this must be the key we will use to communicate between our services.
* 
* 			So, what does this mean? Since the Universal Id will exists only after the user is registered in my database, the
* 			key we must have in all the Order models is the email, and, as the project is when I'm writing this, the Order does
* 			not contain any email. With this in mind, we close this class and going to start the next one making this architectural
* 			change.
* 
* 
*  												CLASS 02_Envolving a service
* 
*  In this class, we discussed about evolving a service. We started to evolve to use email in Orders, and adding it to the
*  schemas of services that needed to know a order has an email (unfortunately, it was all the services). Besides that, we've
*  changed more bout the services and made them all work with our new model. To see more, look for the commits about this class.
* 
* 
*  													CLASS 03_HTTP Server
* 
*  Let's create a service, service-http-ecommerce, that will represent a webpage from where the user will send the first message
*  with it's data to the system. To do that, we'll use the HttpServlet library, and create a service which will start a server 
*  and create a message to send to our queue.
*  
*  FAST DELEGATE
*  
*  	Note that our newOrderServlet has little to no code before sending the message to Kafka. That happens because we are trying 
*  	to achieve a "fast delegate approach": we want to send the messages to the queue as fast as we can, so, if any error happens,
*  	we have our logs to show us where it did, and, even better, we only need to resend the message (if we did a lot of process
*  	before send it, and something went wrong, we'd have to redo all that process, besides send the message again. Not that, with
*  	approach, our work on errors will be reduced).
*  
*   With that in mind, our entry point will usually has little functionality in it, just to send the messages as soon as possible
*  	to not allow the risk that something goes wrong inside of it and we have to redo a process that the user already finished it.
*  
*  
*  													CLASS 04_Broker's clusters
*  
*  SINGLE POINT OF FAILURE DO BROKER
*  
*  	Now we have many services that we can let be running at same time. We can run any of these as many times as we want, and that's
*  	awesome. And, REMEMBER: each one of the consumer groups will consume, in parallel, at most, the number of partitions 
*  	that exists for their given topic.
*  
*  			EXAMPLE: 3 consumers will consume from 3 partitions, and Kafka will define which message goes for which one
*  
*  
*   THE PROBLEM: even if we can have many services running at same time, if the Kafka's broker goes down, it all goes down. Sucks, doesn't it?
*  
*  		GOOD TO KNOW: as we've used send().get(), the dispatcher will be waiting for the broker as much as it need to, so the program will get
*  					  stuck if we send a message with the broker down. Now, if the broker comes back, they will start working again and deliver
* 	 				  it the messages that got stuck, without any work from my part.
*  	
*  	To solve this problem, we MUST RUN MANY INSTANCES OF THE BROKER, as we do for the SERVICES :)
*  
*  
*  CLUSTER REPLICATION
*  
*  	We can reconfigure our broker while it's all running. Incredible, huh?
*  	
*  	To make that work, follow these steps:
*  	
*  		1. Copy the server.properties file to be used by the new broker;
*  
*  		2. Edit the new file to:
*  			2.1. Change the broker.id property;
*  			2.2. Change the log's directory to a new one, just for this broker;
*  			2.3. Change the listener's port to a new empty one;
*  
*  		3. Start a new instance with the new server.properties
*  	
*  	If we only do that and try to kill the first broke to see if Kafka will use the second, it does not work and the
*  	services will be waiting for the first one to come back.
*  	
*  	Why?
*  	
*  	Well, think about it: when we've created the consumer's partitions, they are all localized inside the first broker,
*  	and we didn't configure anything to tell then tha, if that broker is down, they need to search for another. So, of
*  	course, they don't.
*  	
*  	So, how do we deal with this?
*  	
*  	We need to change the ReplicationFactor of our topics. To do that, we can try to use the following command:
*  	
*  		kafka-topics.bat --zookeper localhost:2181 --alter --topic ECOMMERCE_NEW_ORDER --partitions 3 --replication-factor 2
*  	
*  	But that will caught us an error. The replication factor CANNOT, and I quote, "CANNOT BE CHANGED AFTER THE TOPIC'S CREATION".
*  	
*  	So, what now? 
*  	
*  	Open the server.propertie's file from both brokers, and add the following line to then (in the example, they added it bellow the broker.id)
*  	
*  		default.replication.factor = 2;
*  	
*  	After that, stop the kafka and the zookeper, clean the log's directory folder aaaaand... lets give it a try!
*  	
*  		1. Restart Zookeper;
*  		2. Start kafka's first broker;
*  		3. Start kafka's second broker;
*  		4. Confirm there are no topics yet (since you deleted the log's directory, there should not have any)
*  		5. Run two instances of each service and let's get down to business;
*  	
*  	Open a new command line and use the command:
*  
*  						kafka-topics.bat --describe --bootstrap-server localhost:9092
*  
*  	It will show you all the topics created by your services, but, even better, the Leader property (that represents the broker 
*  	where the topic is running) will have other values than 0 (the 0 represented the id of the broker, so you'll see the number
*  	of the id you selected to the new broker here).
*  
*  	Now, when the Leader now falls Kafka will send the messages to any other Leaders available.
*  
*  	Note, thought, that there might be some topics where the "Leader" property is none for the topics "__consumer_offsets". Why? 
*  	Because the offsets, the messages I've already read, where all stored inside the broker that has fallen (if it comes back 
	again, then the process will resume from where it ended).
*  
*  		GOOD TO KNOW: The property ISR, that repeats bellow each of the topic's info when you run kafka-topics's command shows two
*  					  how many replics of that topic are updated until that moment.
*  
*  
*  
*  
*  
*  

				  