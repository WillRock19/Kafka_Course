*
* 											CLASS 01_New Producers and consumers
* 
* 
* 
* 		01. About changes in the service-fraud-detector
* 
* 			Let's start change the service and add a logic to understand if a value of a order is or not a fraud.
*  			Then, we are going to send messages from our service, cause we are baaaaaaad boys.
* 
* 			-> IMPORTANT: If we do execute the LogService BEFORE our the FraudService, who send messages to a new Topic, 
*			the LogService won't hear those messages. Why? Because when we use a pattern to hear the messages, the 
*			pattern will be applied ONLY when the service starts, but not later. In other words: since when it starts
*			we still doesn't have the FraudService with it's new topics running, it will not know those topics exists,
*			and, for that alone, it will not hear it.
*
*		02. About changes in Order of service-fraud-detector
*
*			Since we have a specific Order for each service, we make changes that only make sense inside that project. That
*			generates a trade-in-trade-off scenario: for a first, we don't have to add changes that does not make sense in
*			other scenarios. The problem is: we will have different models for each service. Do our project accepts that scenario?
*			Yes, so it's all sunny in Philly.
* 
* 		03. About the changes in KafkaService
*  
* 			Since we are now throwing exceptions in our consume methods (because we are going to send messages inside of the
* 			consume method from FraudService), we need to threat those exceptions. For now, we only will log in those exceptions.
* 
* 		04. About the new service CreateUserService
* 
* 			Our implementation will assume the service will run ONLY ONCE. This service will save the user information in a 
* 			SQLite database.
* 
* 			As we go further in the implementation of this service, one architectural decision is becoming clear: our user, when 
*			added, will not use the UniversalId as primary key, but the e-mail. When the person give their information, their
* 			identification will be the email, so this must be the key we will use to communicate between our services.
* 
* 			So, what does this mean? Since the Universal Id will exists only after the user is registered in my database, the
* 			key we must have in all the Order models is the email, and, as the project is when I'm writing this, the Order does
* 			not contain any email. With this in mind, we close this class and going to start the next one making this architectural
* 			change.
* 
* 
*  												CLASS 02_Envolving a service
* 
*  In this class, we discussed about evolving a service. We started to evolve to use email in Orders, and adding it to the
*  schemas of services that needed to know a order has an email (unfortunately, it was all the services). Besides that, we've
*  changed more bout the services and made them all work with our new model. To see more, look for the commits about this class.
* 
* 
*  													CLASS 03_HTTP Server
* 
*  Let's create a service, service-http-ecommerce, that will represent a webpage from where the user will send the first message
*  with it's data to the system. To do that, we'll use the HttpServlet library, and create a service which will start a server 
*  and create a message to send to our queue.
*  
*  FAST DELEGATE
*  
*  	Note that our newOrderServlet has little to no code before sending the message to Kafka. That happens because we are trying 
*  	to achieve a "fast delegate approach": we want to send the messages to the queue as fast as we can, so, if any error happens,
*  	we have our logs to show us where it did, and, even better, we only need to resend the message (if we did a lot of process
*  	before send it, and something went wrong, we'd have to redo all that process, besides send the message again. Not that, with
*  	approach, our work on errors will be reduced).
*  
*   With that in mind, our entry point will usually has little functionality in it, just to send the messages as soon as possible
*  	to not allow the risk that something goes wrong inside of it and we have to redo a process that the user already finished it.
*  
*  
*  													CLASS 04_Broker's clusters
*  
*  SINGLE POINT OF FAILURE DO BROKER
*  
*  	Now we have many services that we can let be running at same time. We can run any of these as many times as we want, and that's
*  	awesome. And, REMEMBER: each one of the consumer groups will consume, in parallel, at most, the number of partitions 
*  	that exists for their given topic.
*  
*  			EXAMPLE: 3 consumers will consume from 3 partitions, and Kafka will define which message goes for which one
*  
*  
*   THE PROBLEM: even if we can have many services running at same time, if the Kafka's broker goes down, it all goes down. Sucks, doesn't it?
*  
*  		GOOD TO KNOW: as we've used send().get(), the dispatcher will be waiting for the broker as much as it need to, so the program will get
*  					  stuck if we send a message with the broker down. Now, if the broker comes back, they will start working again and deliver
* 	 				  it the messages that got stuck, without any work from my part.
*  	
*  To solve this problem, we MUST RUN MANY INSTANCES OF THE BROKER, as we do for the SERVICES :)
*  
*  
*  
*  
*  
*  
				  